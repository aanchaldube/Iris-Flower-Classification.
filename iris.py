# -*- coding: utf-8 -*-
"""IRIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Q8WeeiFim0C-XXdM3YoJXEeyKKwaE3r
"""

pip install pandas numpy scikit-learn matplotlib seaborn

print("Load and Inspect the Dataset")

import pandas as pd

# Load the dataset
df = pd.read_csv("IRIS.csv")  # Ensure the file is in the same directory

# Display basic information and first few rows
print(df.info())
print(df.head())

print("Exploratory Data Analysis (EDA)")

import matplotlib.pyplot as plt
import seaborn as sns

# Set style
sns.set(style="whitegrid")

# Plot feature distributions by species
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
features = ["sepal_length", "sepal_width", "petal_length", "petal_width"]

for i, ax in enumerate(axes.flat):
    sns.boxplot(x="species", y=features[i], data=df, ax=ax)
    ax.set_title(f"Distribution of {features[i]} by Species")

plt.tight_layout()
plt.show()

# Correlation heatmap
corr_matrix = df.drop(columns=["species"]).corr()
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

print("Data Preprocessing")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Encode species labels
label_encoder = LabelEncoder()
df["species"] = label_encoder.fit_transform(df["species"])

# Split data into training and testing sets
X = df.drop(columns=["species"])
y = df["species"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Train a Classification Model")

from sklearn.ensemble import RandomForestClassifier

# Train a RandomForestClassifier
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("Model Evaluation")

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Predict on test set
y_pred = model.predict(X_test)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f"Model Accuracy: {accuracy:.2f}\n")
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", conf_matrix)

pip install scikit-learn pandas numpy matplotlib seaborn

from sklearn.model_selection import GridSearchCV

# Define parameter grid for tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

# Best parameters
print("Best Parameters:", grid_search.best_params_)

# Train model with best parameters
best_model = grid_search.best_estimator_

import joblib

# Save the trained model
joblib.dump(best_model, "iris_classifier.pkl")

# Save the label encoder
joblib.dump(label_encoder, "label_encoder.pkl")

print("Model and label encoder saved successfully.")

# Load the trained model and label encoder
model = joblib.load("iris_classifier.pkl")
label_encoder = joblib.load("label_encoder.pkl")  # This file should exist now

print("Model and label encoder loaded successfully.")

pip install fastapi uvicorn

import joblib

# Save the trained model
joblib.dump(best_model, "iris_classifier.pkl")

# Save the label encoder
joblib.dump(label_encoder, "label_encoder.pkl")

print("Model and label encoder saved successfully.")

from fastapi import FastAPI
import joblib
import numpy as np

app = FastAPI()

# Load the trained model
model = joblib.load("iris_classifier.pkl")
label_encoder = joblib.load("label_encoder.pkl")  # If saved separately

@app.get("/")
def home():
    return {"message": "Iris Classification API is running"}

@app.post("/predict/")
def predict_species(sepal_length: float, sepal_width: float, petal_length: float, petal_width: float):
    # Prepare input data
    input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])

    # Predict
    prediction = model.predict(input_data)
    species = label_encoder.inverse_transform(prediction)

    return {"Predicted Species": species[0]}

# Run API with: uvicorn app:app --reload